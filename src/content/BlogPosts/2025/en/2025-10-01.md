---
title: "Recent achievements of the team - Agricultural object detection in complex environments via co-attention and self-knowledge distillation"
date: "2025-10"
---

Our team published the paper “Agricultural Object Detection in Complex Environments via Co-Attention and Self-Knowledge Distillation” in Information Sciences (IF: 6.8, QSCI Zone 2). The School of Computer Engineering and Science at Shanghai University is the first institution listed.

Agricultural object detection is a core task in applications such as smart agriculture and intelligent harvesting. However, factors like lighting variations, background interference, and fruit occlusion in complex environments often lead to reduced detection accuracy. To address this challenge, this paper proposes an efficient detection framework combining Co-Attention and Self-Distillation, effectively enhancing detection accuracy and real-time performance for agricultural object detection in complex scenarios.

<p align="center">
  <img src="/images/indexPic/2025/hzy_Paper1.jpg" style="width:50%"/>
</p>

<div style="display: flex; justify-content: center; gap: 10px; flex-wrap: wrap; margin-bottom: 20px;">
  <img src="/images/indexPic/2025/hzy_Paper2.jpg" style="width:40%" />
  <img src="/images/indexPic/2025/hzy_Paper3.jpg" style="width:40%" />
</div>

Specifically, we propose a Multi-scale Feature Fusion Re-weighting Module (MS-FFRM) that enhances detection accuracy for fruits of varying sizes by strengthening multi-scale feature fusion capabilities. Concurrently, we introduce a Co-Attention Decoder that combines the advantages of cross-attention and self-attention to optimize target query interactions, enabling the model to better handle occluded and overlapping objects. Furthermore, we establish a Hierarchical Self-Distillation mechanism to facilitate knowledge transfer between different layers within the decoder, thereby improving spatial perception and localization robustness. Experiments on four fruit ripeness detection datasets validate our approach: achieving 75.4% accuracy on the tomato dataset, 52.7% on a real-world tomato dataset, 41.5% on the strawberry dataset, and 87.1% on the FruitRipeness dataset.

Essay: [Agricultural object detection in complex environments via co-attention and self-knowledge distillation](https://doi.org/10.1016/j.ins.2025.122711)

Code: [https://github.com/han-yuexing/FMD-DETR](https://github.com/han-yuexing/FMD-DETR)

<div style="display:flex; flex-direction:column; justify-content:center; align-items:center; text-align:center; margin-top:20px;">
    <img src="/images/indexPic/2025/hzy.jpg" style="width:40%;" />
    <div>Huang Zhiyi</div>
</div>
