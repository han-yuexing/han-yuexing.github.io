---
title: "Recent achievements of the team - using deep learning to predict the thermal conductivity of tetragonal YSZ coatings doped with Al2O3"
date: "2024-04"
---

Our team has published a paper titled 'Thermal Conductivity Prediction of Al2O3 Doped Tetragonal YSZ Coatings Using Deep Learning' in the international journal Journal of the European Ceramic Society (IF: 5.7, Chinese Academy of Sciences). The paper is authored by the School of Computer Engineering and Science at Shanghai University.

<p align="center">
  <img src="/images/indexPic/2023/hsf_Paper.png" alt="论文封面" />
</p>

Predicting material image performance based on deep learning faces challenges such as data scarcity, inability to simultaneously extract local and global features of material images, and discovering correlations between features. In the field of materials, due to factors such as manufacturing costs and commercial protection, it is not possible to obtain data in bulk like obtaining natural scene images, which makes it difficult to directly apply deep learning models to the materials field due to insufficient data volume. On the other hand, unlike natural scene images, material images often have very fine and complex texture structures due to their own characteristics, and macroscopic performance is not only affected by local microscopic structures. The correlation between features and the interaction between structures, that is, global features, are also very important. Most existing deep learning methods often directly apply CNN models that perform well on natural scene images to the field of materials without targeted optimization. Due to the fixed size of the convolution kernel, CNN's receptive field is limited and often only extracts local features of the image, ignoring global features. Therefore, the algorithm suffers from insufficient training due to the scarcity of data and the inability to simultaneously extract local and global features, resulting in insufficient prediction accuracy and poor robustness. To address these issues, this paper proposes a dual structure feature extraction and multi-scale attention fusion network (RCFNet). This model adopts a dual branch structure of global feature extraction module and local feature extraction module, independently extracting global and local features of material images without damaging the original modeling of their respective features. By proposing a multi-scale attention fusion module (Merge), the global and local features extracted at each scale are fused, and the fusion module accumulates information from the previous fusion result. The final fused features are fed into FCNN for processing and prediction results are obtained. The following is a schematic diagram of the structure of the multi-scale attention fusion module.

<p align="center">
  <img src="/images/indexPic/2023/hsf_Paper1.png" alt="模块结构示意图" />
</p>

For both global and local features at each scale, the SCSE attention mechanism is first employed to simultaneously stimulate important information in both channel and spatial dimensions, highlighting the most critical features and assigning significant weights. Next, global features with global semantics are further processed through channel attention mechanisms, while local features with local semantic information are further processed through spatial attention mechanisms. Subsequently, high-dimensional spatial mapping and nonlinear transformation are performed to obtain the fusion result of the current stage. The proposed method takes into account both local and global feature extraction of material images, with the Merge module performing multi-level feature fusion, multi attention continuously focusing on key features, suppressing noise information, reducing information loss, and reducing the model's dependence on a large amount of training data. In the field of material images with scarce samples, very impressive prediction results have also been obtained.

Essay: [Thermal Conductivity Prediction of Al2O3-Doped Tetragonal YSZ Coatings Using Deep Learning](https://doi.org/10.1016/j.jeurceramsoc.2024.04.057)

Our code and paper are both publicly available at: [https://github.com/han-yuexing/RCFNet_Conv_Resnet50_MHSA/tree/main](https://github.com/han-yuexing/RCFNet_Conv_Resnet50_MHSA/tree/main)
</div>

<div style="display:flex; flex-direction:column; justify-content:center; align-items:center; text-align:center; margin-top:20px;">
    <img src="/images/indexPic/2023/hsf.png" style="width:60%;" />
    <div>Han Sifan</div>
</div>